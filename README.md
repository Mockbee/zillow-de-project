# zillow-data-engineering-project

# ğŸ¡ Zillow Data Engineering Project

This project demonstrates the design and implementation of a modern data pipeline using **Databricks**, **Azure Blob Storage**, and Zillow real estate data. The pipeline is structured using the **Medallion Architecture** (Bronze â†’ Silver â†’ Gold) to enable scalable and reliable processing.

---

### ğŸ“Œ Project Architecture

![Architecture Diagram](https://github.com/Mockbee/zillow-de-project/blob/main/Zillow%20DE%20Architecture%20Diagram.png)

---

### ğŸ“¦ Data Source

We integrate with publicly available **Zillow housing data**, which includes:

- **Property Information:** Core housing attributes such as ID, address, coordinates, and type.
- **Tax & Price Data:** Historical pricing and taxation records for properties.

The raw datasets are fetched from APIs and processed through the Medallion architecture layers.

---

### ğŸ› ï¸ Tools & Services Used

| Tool/Service         | Role                                                                 |
|----------------------|----------------------------------------------------------------------|
| **Databricks**       | Notebook-based development, orchestration, transformation (PySpark) |
| **Azure Blob Storage** | Stores raw (Bronze), cleaned (Silver), and curated (Gold) data       |
| **Delta Lake**       | ACID-compliant storage for reliable data operations                 |
| **Databricks Workflows** | Orchestrates multi-stage job execution and scheduling            |

---

### ğŸ§± Medallion Architecture Layers

1. **Bronze Layer (Raw Ingestion):**
   - Ingests raw Zillow data (property, price, tax) in JSON/CSV.
   - Stores exact payload for traceability and recovery.

2. **Silver Layer (Transformation):**
   - Parses, flattens, and enriches the data using PySpark.
   - Adds metadata and ensures type consistency.

3. **Gold Layer (Enriched Data):**
   - Outputs business-ready tables for analytics, e.g., pricing trends by region.

---

### ğŸ” Pipeline Flow

The project is orchestrated with **Databricks Workflows**, which executes tasks in a DAG structure:

